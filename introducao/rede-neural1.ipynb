{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.ToTensor() # definindo a conversão de imagem para tensor\n",
    "\n",
    "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)  # carrega a parte de treino do dataset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)  # cria um buffer para pegar os dados por partes\n",
    "\n",
    "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform)  # carrega a parte de validação\n",
    "valloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)  # cria um buffer para pegar os dados por partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10f6f925a60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "imagens, etiquetas = next(dataiter)\n",
    "plt.imshow(imagens[0].numpy().squeeze(), cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(imagens[0].shape)  # verificando as dimensões do tensor de cada imagem\n",
    "print(etiquetas[0].shape)  # verificando as dimensões do tensor de cada estiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 128)  # camada de entrada, 784 neurônios que se ligam a 128\n",
    "        self.linear2 = nn.Linear(128, 64)  # camada interna 1, 128 neurônios que se ligam a 64\n",
    "        self.linear3 = nn.Linear(64, 10)  # camada interna 2, 64 neurônios que se ligam a 10\n",
    "\n",
    "        # para a camada de saida não é necessário definir nada pois só é preciso pegar o output da camada interna2\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.linear1(X))  # função de ativação da camada de entrada para a camada interna 1\n",
    "        X = F.relu(self.linear2(X))  # função de ativação de camada interna 1 para camada interna 2\n",
    "        X = self.linear3(X)  # função de ativação de camada interna 2 para a camada de saida, nesse caso f(x) = x\n",
    "        return F.log_softmax(X, dim=1)  # dados utilizados para calcular a perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(modelo, trainloader, device):\n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # define a politica de atualização dos pesos e bias\n",
    "    inicio = time()  # timer para saber quanto tempo levou o treino\n",
    "\n",
    "    criterio = nn.NLLLoss()  # definindo o criterio para calcular a perda\n",
    "    EPOCHS = 10  # numero de epochs que o algoritimo rodará\n",
    "    modelo.train()  # ativando o modo de treinamento do modelo\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0  # inicialização da perda acumulada da epoch em questão\n",
    "\n",
    "        for imagens, etiquetas in trainloader:\n",
    "            imagens = imagens.view(imagens.shape[0], -1)  # convertendo as imagens para \"vetores\" de 28*28 para ficarem compativeis\n",
    "            otimizador.zero_grad() # zerando os gradientes por conta do ciclo anterior\n",
    "\n",
    "            output = modelo(imagens.to(device))  # colocando os dados no modelo\n",
    "            perda_instantanea = criterio(output, etiquetas.to(device))  # calculando a perda da epoch em questão \n",
    "\n",
    "            perda_instantanea.backward()  # back propagation a partir da perda\n",
    "\n",
    "            otimizador.step()  # atualizando os pesos e a bias\n",
    "\n",
    "            perda_acumulada += perda_instantanea.item()  # atualização da perda acumulada\n",
    "\n",
    "        else:\n",
    "            print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
    "    print(\"\\nTempo de treino (em minutos) = \",(time()-inicio)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao(modelo, valloader, device):\n",
    "    conta_corretas, conta_todas = 0, 0\n",
    "    \n",
    "    for imagens, etiquetas in valloader:\n",
    "        for i in range(len(etiquetas)):\n",
    "            img = imagens[i].view(1, 784)\n",
    "            # desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
    "            with torch.no_grad():\n",
    "                logps = modelo(img.to(device))  # output do modelo em escala logaritmica\n",
    "\n",
    "            ps = torch.exp(logps)  # converte output para escala normal\n",
    "            probab = list(ps.cpu().numpy()[0])\n",
    "            etiqueta_pred = probab.index(max(probab))  # converte o tensor em um numero\n",
    "            etiqueta_certa = etiquetas.numpy()[i]\n",
    "            if(etiqueta_certa == etiqueta_pred):  # compara a previsão com valor correto\n",
    "                conta_corretas += 1\n",
    "            conta_todas += 1\n",
    "\n",
    "    print(\"Total de imagens testadas =\", conta_todas)\n",
    "    print(\"\\nPrecisão de modelo = {}%\".format(conta_corretas*100/conta_todas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelo.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
